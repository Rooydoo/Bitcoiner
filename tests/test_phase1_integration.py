"""Phase 1çµ±åˆãƒ†ã‚¹ãƒˆ"""

import sys
from pathlib import Path
import time

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger import setup_logger
from utils.resource_monitor import get_resource_monitor
from data.storage.sqlite_manager import get_db_manager
from data.processor.indicators import TechnicalIndicators
import pandas as pd
import numpy as np

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = setup_logger('phase1_test', 'phase1_test.log', console=True)


def test_phase1_integration():
    """Phase 1çµ±åˆãƒ†ã‚¹ãƒˆ"""
    logger.info("=" * 70)
    logger.info("Phase 1 çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    logger.info("=" * 70)

    monitor = get_resource_monitor()

    # åˆæœŸãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹
    logger.info("\n[1] åˆæœŸãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹:")
    monitor.log_current_status()

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
    logger.info("\n[2] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ:")
    db = get_db_manager()

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    now = int(time.time())
    sample_data = pd.DataFrame({
        'timestamp': [now - i*3600 for i in range(100, 0, -1)],  # éå»100æ™‚é–“
        'open': np.random.uniform(49000, 51000, 100),
        'high': np.random.uniform(50000, 52000, 100),
        'low': np.random.uniform(48000, 50000, 100),
        'close': np.random.uniform(49000, 51000, 100),
        'volume': np.random.uniform(1000, 5000, 100)
    })

    # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
    db.insert_ohlcv(sample_data, 'BTC/USDT', '1h')
    logger.info("  âœ“ BTC/USDT 1h ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥å®Œäº† (100ä»¶)")

    db.insert_ohlcv(sample_data, 'ETH/USDT', '1h')
    logger.info("  âœ“ ETH/USDT 1h ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥å®Œäº† (100ä»¶)")

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    retrieved = db.get_latest_ohlcv('BTC/USDT', '1h', limit=50)
    logger.info(f"  âœ“ ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ: {len(retrieved)}ä»¶å–å¾—")

    # DBã‚µã‚¤ã‚ºç¢ºèª
    sizes = db.get_database_sizes()
    logger.info(f"  âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {sizes}")

    # ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹ï¼ˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥å¾Œï¼‰
    logger.info("\n[3] ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥å¾Œã®ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹:")
    mem_after_db = monitor.get_memory_usage()
    logger.info(f"  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {mem_after_db.get('process_mb')} MB ({mem_after_db.get('process_percent')}%)")

    # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    logger.info("\n[4] æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ:")
    ti = TechnicalIndicators()

    # å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ï¼ˆãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ï¼‰
    large_data = pd.DataFrame({
        'timestamp': range(1000),
        'open': np.random.uniform(49000, 51000, 1000),
        'high': np.random.uniform(50000, 52000, 1000),
        'low': np.random.uniform(48000, 50000, 1000),
        'close': np.random.uniform(49000, 51000, 1000),
        'volume': np.random.uniform(1000, 5000, 1000)
    })

    start_time = time.time()
    df_with_indicators = ti.calculate_all(large_data)
    calc_time = time.time() - start_time

    logger.info(f"  âœ“ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œäº†: {len(df_with_indicators)}è¡Œ")
    logger.info(f"  âœ“ è¨ˆç®—æ™‚é–“: {calc_time:.2f}ç§’")
    logger.info(f"  âœ“ æŒ‡æ¨™æ•°: {len(df_with_indicators.columns) - len(large_data.columns)}å€‹è¿½åŠ ")

    # ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹ï¼ˆè¨ˆç®—å¾Œï¼‰
    logger.info("\n[5] æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¾Œã®ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹:")
    mem_after_calc = monitor.get_memory_usage()
    logger.info(f"  âœ“ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {mem_after_calc.get('process_mb')} MB ({mem_after_calc.get('process_percent')}%)")

    # ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡
    mem_increase = mem_after_calc.get('process_mb', 0) - mem_after_db.get('process_mb', 0)
    logger.info(f"  âœ“ ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡: {mem_increase:.2f} MB")

    # ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ãƒã‚§ãƒƒã‚¯
    logger.info("\n[6] ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ãƒã‚§ãƒƒã‚¯:")
    warnings = monitor.check_resource_limits(
        cpu_threshold=80.0,
        memory_threshold=50.0,  # 50%ï¼ˆ8GBã®åŠåˆ†=4GBï¼‰
        disk_threshold=90.0
    )

    if not any(warnings.values()):
        logger.info("  âœ“ å…¨ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ãŒæ­£å¸¸ç¯„å›²å†…ã§ã™")
    else:
        logger.warning(f"  âš  ãƒªã‚½ãƒ¼ã‚¹è­¦å‘Š: {warnings}")

    # æœ€çµ‚ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹
    logger.info("\n[7] æœ€çµ‚ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ…‹:")
    monitor.log_current_status()

    # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
    logger.info("\n" + "=" * 70)
    logger.info("Phase 1 çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
    logger.info("=" * 70)

    logger.info("\nâœ… ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    logger.info(f"  - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {len(retrieved)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")
    logger.info(f"  - æŠ€è¡“æŒ‡æ¨™è¨ˆç®—: {calc_time:.2f}ç§’ã§1000è¡Œå‡¦ç†")
    logger.info(f"  - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: {mem_after_calc.get('process_mb')} MBä½¿ç”¨ï¼ˆ{mem_after_calc.get('process_percent')}%ï¼‰")
    logger.info(f"  - ãƒªã‚½ãƒ¼ã‚¹è­¦å‘Š: {'ãªã—' if not any(warnings.values()) else 'ã‚ã‚Š'}")

    # æ¨å¥¨äº‹é …
    logger.info("\nğŸ“Š Phase 1 æˆæœç‰©:")
    logger.info("  âœ“ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ")
    logger.info("  âœ“ Binance APIé€£æºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")
    logger.info("  âœ“ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ20ç¨®é¡ä»¥ä¸Šï¼‰")
    logger.info("  âœ“ ãƒ‡ãƒ¼ã‚¿åé›†ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼")
    logger.info("  âœ“ ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼")
    logger.info("  âœ“ ãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ")
    logger.info("  âœ“ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ")

    logger.info("\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 2ï¼‰:")
    logger.info("  - MLãƒ¢ãƒ‡ãƒ«ï¼ˆHMMã€LightGBMï¼‰ã®å®Ÿè£…")
    logger.info("  - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    logger.info("  - ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰")
    logger.info("  - ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")

    logger.info("\n" + "=" * 70)


if __name__ == "__main__":
    test_phase1_integration()
